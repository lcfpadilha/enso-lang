# EnsÅ (å††ç›¸)

**The AI-Native Systems Language.**

EnsÅ is a statically-typed, compiled language designed for the Agentic Era. It treats Large Language Models (LLMs) as reliable CPU functions, abstracting away the complexity of API clients, JSON schema generation, retry logic, and structured parsing.

**Write Intent. Compile to Infrastructure.**

---

## âš¡ Quick Start

### 1. The Code (`hiring.enso`)

```rust
// 1. Define your data shape (The "Contract")
struct Skill {
    name: String,
    level: Enum<"Beginner", "Intermediate", "Expert">
}

struct Candidate {
    name: String,
    skills: List<Skill>
}

// 2. Define your Intelligence (The "Declarative Logic")
ai fn extract_resume(text: String) -> Result<Candidate, AIError> {
    instruction: "Extract name and skills. Be strict with seniority levels."
    model: "gemini-flash-latest"
}

// 3. Define your Orchestration (The "CPU Logic")
fn main() {
    let raw_text = "Hi, I'm Neo. I know Kung Fu (Expert) and Python (Beginner).";
    
    // The 'match' statement guarantees you handle success AND failure.
    match extract_resume(raw_text) {
        Ok(candidate) => {
            print("Hired: " + candidate.value.name);
        },
        Err(error) => {
            print("Parsing failed. Reason:");
            print(error.message);
        }
    }
}
```

### 2. Run It

```bash
enso run hiring.enso
```

### Output

```text
INFO: Agent 'extract_resume' -> gemini-flash-latest
  ğŸ’° Cost: $0.000528 | â±ï¸  Latency: 1.15s

Hired: Neo
```

### Learn the Syntax

ğŸ‘‰ **[QUICK_REFERENCE.md](QUICK_REFERENCE.md)** - Complete grammar guide with all syntax rules, types, functions, and best practices. **Start here for syntax questions.**

---

## ğŸ“š Cookbook Examples

The `examples/` folder contains **production-ready examples** that serve as a cookbook for common use cases. Each example demonstrates real-world patterns you can adapt for your own projects:

| Example | Focus | Use Cases |
|---------|-------|----------|
| **1. Structured Data Extraction** | Type-safe extraction, batch processing | Resume parsing, form filling, data migration, document processing |
| **2. Classification & Decision Making** | Enums, constrained outputs, moderation | Sentiment analysis, content moderation, email routing, ticket classification |
| **3. Large Context Windows** | Long document processing, web agents | Document analysis, competitive intelligence, log analysis, research |
| **4. Complete Hiring Workflow** | Full pipeline, multiple AI functions | End-to-end hiring automation, multi-step decision making |

**Try them all:**
```bash
enso run examples/1_structured_data_extraction.enso
enso run examples/2_classification_decision_making.enso
enso run examples/3_large_context_web_agent.enso
enso run examples/4_complete_hiring_workflow.enso
```

Each example includes:
- âœ… Real-world scenario
- âœ… Production-ready code
- âœ… Comments explaining the pattern
- âœ… Runnable with `enso.py run` command

---

## Why EnsÅ?

### 1. Type-Safe Intelligence
EnsÅ compiles strict types into **JSON Schemas** automatically. If the LLM returns data that doesn't match your `struct`, EnsÅ catches it before it hits your logic.

### 2. Error as a First-Class Citizen
AI is non-deterministic. It *will* fail. EnsÅ's `Result<T, E>` type and `match` syntax force you to handle refusals, timeouts, and hallucinations at compile time. No more crashing in production because the model returned "I cannot answer that."

### 3. Vendor Agnostic
Switch from `gemini-1.5-flash` to `gpt-4o` by changing one line of code. The compiler handles the API differences.

---

## ğŸ›  Features

### ğŸ§  AI Functions (ai fn)

Forget import openai. Define a function, give it an instruction, and declare what you want back. The compiler handles the rest.

```rust
ai fn summarize(text: String) -> String {
    instruction: "Summarize in 3 bullet points."
}
```

### ğŸ”’ Structured Types (`struct`)

EnsÅ compiles strict types into **Pydantic Models** and automatically generates **JSON Schemas** to force the LLM to return valid data.

```rust
struct User {
    name: String,
    age: Int,
    tags: List<String>
}
```

### ğŸ§ª Native Testing & Mocking

Test your logic without hitting the API. EnsÅ has a built-in test runner with `mock` support.

```rust
test "User parsing logic" {
    // Force the AI to return this specific data
    mock extract_resume => Candidate { name: "Trinity", skills: [] };
    
    let res = extract_resume("irrelevant text");
    assert res.value.name == "Trinity";
}
```

### ğŸ”Œ Standard CPU Functions

Write standard imperative code to glue your AI steps together.

```rust
fn process(data: String) -> Int {
    if data == "" {
        return 0;
    }
    let parsed = ai_func(data);
    return parsed.value.score;
}
```

### âš™ï¸ Concurrent Batch Operations

Process multiple items through an AI function in parallel. Returns `List<Result<T, E>>` with both successes and failures.

```rust
ai fn analyze(text: String) -> Result<Sentiment, AIError> {
    instruction: "Analyze sentiment for text",
    model: "gpt-4o"
}

test "Batch Processing" {
    let texts = ["Great day", "Bad timing", "It is okay"];
    concurrent analyze(text) for text in texts;  // Process all in parallel
    
    // Results: List<Result<Sentiment, AIError>>
    for result in analyze_results {
        match result {
            Ok(sentiment_data) => {
                print(sentiment_data.value.mood);
            },
            Err(error) => {
                print(error.message);
            }
        }
    }
}
```

**Key Features:**
- âœ… True parallel execution using `asyncio.gather()`
- âœ… Composable error handling (collects both successes and failures)
- âœ… Backward compatible with single-function calls
- âœ… Full mock support for testing

---

## ğŸš€ Prompt Engineering Superpowers

EnsÅ  includes powerful features for advanced prompt engineering, enabling you to build AI systems with more accuracy.

### 1. Variable Interpolation

Inject function parameters directly into your prompts:

```rust
ai fn extract(resume: String, target_role: String) -> Candidate {
    instruction: "Extract {target_role} candidate from resume: {resume}",
    model: "gpt-4o"
}

// Automatically becomes:
// "Extract Senior Backend Engineer candidate from resume: John: 10y Python..."
```

### 2. System Instructions

Separate role-based context from task instructions:

```rust
ai fn assess_fit(resume: String, company_culture: String) -> Candidate {
    system_instruction: "You are a world-class technical recruiter with 20 years of experience.",
    instruction: "Assess fit for our {company_culture} team. Resume: {resume}",
    model: "gpt-4o"
}
```

### 3. Few-Shot Examples

Include examples to dramatically improve accuracy:

```rust
ai fn match_candidate(resume: String, seniority: String) -> Candidate {
    system_instruction: "You are a top technical recruiter.",
    instruction: "Match {seniority} candidate. Resume: {resume}",
    
    // Few-shot examples guide the LLM
    examples: [
        (
            resume: "John: 10y Python, led 3 teams, mentored 5+ engineers",
            seniority: "Senior",
            expected: Candidate { 
                name: "John", 
                match_score: 92 
            }
        ),
        (
            resume: "Jane: Fresh grad, bootcamp, 1 toy project",
            seniority: "Senior",
            expected: Candidate { 
                name: "Jane", 
                match_score: 15 
            }
        )
    ],
    
    temperature: 0.1,  // Low temperature for structured outputs
    model: "gpt-4o"
}
```

---

## ğŸ— Architecture

EnsÅ is a **Transpiled Language**.

1. **Source Code (`.enso`):** Your clean, readable logic.
2. **Compiler:** Uses Lark to parse the AST.
3. **Transpilation:** Converts EnsÅ AST into Python + Pydantic + Requests.
4. **Runtime:** The generated Python code is executed, managing API keys (`OPENAI_API_KEY`, `GEMINI_API_KEY`) and HTTP connections automatically.

---

## ğŸ“¦ Installation & Setup

### 1. Clone & Install Dependencies

```bash
git clone [https://github.com/your-repo/enso.git](https://github.com/your-repo/enso.git)
cd enso
```

### 2. Configure API Keys

```bash
export GEMINI_API_KEY="your-key-here"
export OPENAI_API_KEY="your-key-here"
```

### 3. Setup the enso Command

Run the following command in the project root to install the CLI tool in editable mode. This makes enso globally available while allowing you to modify the source code.

```bash
pip install -e .
```

### Initialize a Project

```bash
enso init
```

---

## ğŸ’° Cost Estimation with `enso analyse`

**Estimate AI costs before spending money.** The `enso analyse` command is a killer feature for cost planning:

```bash
# Analyze your code without making API calls
enso analyse hiring.enso
```

**Output:**
```
ğŸ¤– AI FUNCTION CALLS: 24 total calls

CALL BREAKDOWN:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Function                â”‚ Calls â”‚ Model                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ extract_resume          â”‚ 8     â”‚ gemini-2.5-flash-li â”‚
â”‚ classify_seniority      â”‚ 6     â”‚ gemini-flash-latest  â”‚
â”‚ evaluate_fit            â”‚ 6     â”‚ gemini-flash-latest  â”‚
â”‚ generate_recommendation â”‚ 4     â”‚ gpt-4o               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ’° ESTIMATED COST (if run with real API):
â”‚ gemini-2.5-flash-lite   â”‚ 8     â”‚ $0.0045  â”‚
â”‚ gemini-flash-latest     â”‚ 12    â”‚ $0.0060  â”‚
â”‚ gpt-4o                  â”‚ 4     â”‚ $0.0320  â”‚
â”‚ TOTAL:                  â”‚       â”‚ $0.0425  â”‚
```

**Why this matters:**
- ğŸ” **Verify your code works** without API costs
- ğŸ’­ **Plan costs before scaling** â€“ know the bill before you run production batches
- ğŸ“Š **Export to JSON** for CI/CD integration â€“ `enso analyse main.enso --save-report report.json`
- ğŸ›¤ï¸ **Debug execution path** if needed â€“ `enso analyse main.enso --show-path`
- âœ… **Supports imports** â€“ analyzes entire project including dependencies

**How it works:** Compiles your `.enso` file, injects automatic mocks for all AI functions, executes with tracking, and reports call counts and estimated costsâ€”*no API calls made*.

---

## ğŸ’» CLI Usage

| Command | Description | Example |
| :--- | :--- | :--- |
| `enso init` | Creates a new project with `main.enso` | `enso init` |
| `enso run` | Compiles and executes a file | `enso run main.enso` |
| `enso run -` | Reads source code from stdin (pipe support) | `cat script.enso \| enso run -` |
| `enso test` | Runs internal tests (mocks only) | `enso test main.enso` |
| `enso test --include_ai` | Runs tests allowing real AI calls | `enso test main.enso --include_ai` |
| `enso analyse` | Estimates cost without running AI (with mocks) | `enso analyse main.enso` |
| `enso analyse --show-path` | Same as above, with detailed execution trace | `enso analyse main.enso --show-path` |
| `enso analyse --save-report` | Save analysis as JSON for CI/CD | `enso analyse main.enso --save-report report.json` |
| `enso update` | Updates local model pricing/registry | `enso update` |
| `enso --verbose <cmd>` | Enable debug output, model cost and model calls on stderr | `enso --verbose run main.enso 2>&1` |

---

## ğŸ¨ Syntax Highlighting

### VS Code

Enso files (`.enso`) have full syntax highlighting support in VS Code.

**Installation:**
1. Open VS Code **Extensions** panel (`Ctrl+Shift+X`)
2. Click the menu button (â‹¯) â†’ **"Install from VSIX..."**
3. Navigate to `enso-vscode/enso-language-support-0.1.0.vsix` in the project root
4. Click **"Install"**
5. Reload VS Code (`Ctrl+Shift+P` â†’ "Reload Window")

---

## ğŸ“‹ Phase 2: Future Roadmap

These features are designed but deferred for post-MVP iterations:

### Result Type Enhancements
- [ ] **Monadic Operations** â€“ Add `bind()` / `flatMap()` for composing Result-returning operations
  - Enables: `analyze(text).bind(classify).bind(score)` for chaining without explicit matching
- [ ] **Advanced Type Checks** â€“ Better pattern matching with guards
  - Enables: `result.is_ok()`

### Concurrency Improvements
- [ ] **Per-Item Timeouts** â€“ Configure timeout per concurrent item
- [ ] **Progress Callbacks** â€“ Monitor long-running batch operations
- [ ] **Automatic Retry Logic** â€“ Retry failed items with exponential backoff
- [ ] **Rate Limiting** â€“ Control QPS to avoid API throttling

### Library Generation
- [ ] **`pub fn` Visibility** â€“ Mark functions for export vs. internal-only
- [ ] **Module Hierarchy** â€“ Preserve directory structure in generated package
  - `src/sentiments.enso` â†’ `ai_lib.sentiments.analyze()`
- [ ] **Auto-Generated Docstrings** â€“ Extract from instructions for IDE tooltips
- [ ] **Type Stubs (.pyi)** â€“ For better IDE autocomplete and type checking

### Language Features
- [x] **âœ… Variable Interpolation in Prompts** â€“ `"Analyze {text} with context {context}"` (DONE)
- [x] **âœ… System Instructions** â€“ Separate role context from task instructions (DONE)
- [x] **âœ… Few-Shot Examples** â€“ Guide LLM with examples for better accuracy (DONE)
- [ ] **Multi-Model Routing** â€“ Route based on cost/latency/capability
  - `model: select("gpt-4o" if complex else "gpt-4o-mini")`
- [ ] **Streaming Responses** â€“ Stream tokens for real-time feedback
- [ ] **Prompt Caching** â€“ Reuse expensive prompt prefixes across calls
- [ ] **Tool Use / Function Calling** â€“ Define functions for LLM to call back

### Developer Experience
- [ ] **SDK Generation** â€“ Generate TypeScript/Go SDKs from EnsÅ definitions
- [ ] **Observability** â€“ Built-in tracing, cost reporting, analytics
- [ ] **Local Development** â€“ Mock LLM responses with recorded interactions
- [ ] **Hot Reload** â€“ Modify EnsÅ files and restart without recompiling

### Performance & Reliability
- [ ] **Compiled Binaries** â€“ Compile to native binaries (PyO3 / maturin)
- [ ] **Better Error Messages** â€“ With suggestions and error codes
- [ ] **Cost Forecasting** â€“ Estimate total cost before running batch
- [ ] **Circuit Breaker** â€“ Fail-safe when errors exceed threshold

---

*EnsÅ is currently in Alpha. Built for the stress test of the future.*
